{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X-DX0ddMlMo3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from scipy.stats import randint\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Movie Data from extracted TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mqPdlUrPwx3q"
   },
   "outputs": [],
   "source": [
    "# Define a list of file paths for CSV files to be loaded\n",
    "file_paths = [\n",
    "    'Yearly\\movies2013.csv',\n",
    "    'Yearly\\movies2014.csv',\n",
    "    'Yearly\\movies2015.csv',\n",
    "    'Yearly\\movies2016.csv',\n",
    "    'Yearly\\movies2017.csv',\n",
    "    'Yearly\\movies2018.csv',\n",
    "    'Yearly\\movies2019.csv',\n",
    "    'Yearly\\movies2020.csv',\n",
    "    'Yearly\\movies2021.csv',\n",
    "    'Yearly\\movies2022.csv',\n",
    "    'Yearly\\movies2023.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Load each CSV file into a dataframe and store them in the 'dataframes' list\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "TMDB_df = pd.concat(dataframes)\n",
    "\n",
    "# Remove duplicate rows based on the 'imdb_id' column, keeping the first occurrence\n",
    "TMDB_df.drop_duplicates(subset=['imdb_id'], keep='first', inplace=True)\n",
    "\n",
    "# Now, 'TMDB_df' contains the merged data from all CSV files without duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'backdrop_path', 'belongs_to_collection', 'budget', 'genres',\n",
       "       'homepage', 'id', 'imdb_id', 'original_language', 'original_title',\n",
       "       'overview', 'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count', 'keywords', 'cast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TMDB_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AHSfNldCvLoE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>revenue</th>\n",
       "      <th>adult</th>\n",
       "      <th>backdrop_path</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
       "      <td>14000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt2637294</td>\n",
       "      <td>en</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>When Lou, who has become the \"father of the In...</td>\n",
       "      <td>6.575393</td>\n",
       "      <td>...</td>\n",
       "      <td>Hot Tub Time Machine 2</td>\n",
       "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
       "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
       "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
       "      <td>12314651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
       "      <td>40000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt0368933</td>\n",
       "      <td>en</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>8.248895</td>\n",
       "      <td>...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
       "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
       "      <td>95149435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3300000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://sonyclassics.com/whiplash/</td>\n",
       "      <td>tt2582802</td>\n",
       "      <td>en</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>64.299990</td>\n",
       "      <td>...</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
       "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
       "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
       "      <td>13092000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1200000</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
       "      <td>http://kahaanithefilm.com/</td>\n",
       "      <td>tt1821480</td>\n",
       "      <td>hi</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
       "      <td>3.174936</td>\n",
       "      <td>...</td>\n",
       "      <td>Kahaani</td>\n",
       "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
       "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
       "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
       "      <td>16000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt1380152</td>\n",
       "      <td>ko</td>\n",
       "      <td>마린보이</td>\n",
       "      <td>Marine Boy is the story of a former national s...</td>\n",
       "      <td>1.148070</td>\n",
       "      <td>...</td>\n",
       "      <td>Marine Boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
       "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
       "      <td>3923970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28446</th>\n",
       "      <td>800227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>http://a24films.com/films/all-dirt-roads-taste...</td>\n",
       "      <td>tt11534720</td>\n",
       "      <td>en</td>\n",
       "      <td>All Dirt Roads Taste of Salt</td>\n",
       "      <td>Tender caresses and enveloping embraces are po...</td>\n",
       "      <td>6.058000</td>\n",
       "      <td>...</td>\n",
       "      <td>All Dirt Roads Taste of Salt</td>\n",
       "      <td>['woman director', 'visual poem', 'mississippi']</td>\n",
       "      <td>['Charleen McClure', 'Sheila Atim', 'Moses Ing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41000</td>\n",
       "      <td>False</td>\n",
       "      <td>/p65KvZIFrlYxB3LZU2e5WtYvmfZ.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29447</th>\n",
       "      <td>1187038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>[{'id': 9648, 'name': 'Mystery'}, {'id': 80, '...</td>\n",
       "      <td>https://www.pioneerpicture.com</td>\n",
       "      <td>tt27097230</td>\n",
       "      <td>kn</td>\n",
       "      <td>Manduka</td>\n",
       "      <td>A girl suffering from schizophrenia accidental...</td>\n",
       "      <td>3.045000</td>\n",
       "      <td>...</td>\n",
       "      <td>Manduka</td>\n",
       "      <td>['india', 'kannada', 'accidental crime', 'sand...</td>\n",
       "      <td>['Anjala', 'Madhan', 'Bhushan', 'Mysore raju',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>/oXLzPSTw5YoAUU7XcXf88BjICq2.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29597</th>\n",
       "      <td>1065835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5404446</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 80, 'n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt15654502</td>\n",
       "      <td>hi</td>\n",
       "      <td>The Ladykiller</td>\n",
       "      <td>When a small-town playboy falls in love for a ...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>The Ladykiller</td>\n",
       "      <td>['mysterious woman', 'erotic thriller', 'suspe...</td>\n",
       "      <td>['Bhumi Pednekar', 'Arjun Kapoor', 'Priyanka B...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>456</td>\n",
       "      <td>False</td>\n",
       "      <td>/eyDx5sUQscDqDC3PdRbsBNH3BxB.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30336</th>\n",
       "      <td>947650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 10751...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tt14506102</td>\n",
       "      <td>cs</td>\n",
       "      <td>Tonko, Slávka a kúzelné svetlo</td>\n",
       "      <td>Tony has been glowing since the day he was bor...</td>\n",
       "      <td>2.102000</td>\n",
       "      <td>...</td>\n",
       "      <td>Tony, Shelly and the Magic Light</td>\n",
       "      <td>['stop motion']</td>\n",
       "      <td>['Michael Polák', 'Antonie Baresová', 'Ivana U...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191018</td>\n",
       "      <td>False</td>\n",
       "      <td>/rFdlSLjaf6qrGChWr9gje6eTcbf.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31557</th>\n",
       "      <td>1116492</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 27, 'name...</td>\n",
       "      <td>http://www.trettfilms.com</td>\n",
       "      <td>tt27351080</td>\n",
       "      <td>en</td>\n",
       "      <td>Dial</td>\n",
       "      <td>Dani cares for her ill mother who suddenly die...</td>\n",
       "      <td>1.038000</td>\n",
       "      <td>...</td>\n",
       "      <td>Dial</td>\n",
       "      <td>['psychological thriller', 'phone', 'carer']</td>\n",
       "      <td>['Olivia Bourne', 'Denise Stephenson', 'Greg L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>/6mkQa7QVIC5LLx7tJr7FCgVbyc3.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8266 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                              belongs_to_collection    budget  \\\n",
       "0            1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
       "1            2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
       "2            3                                                NaN   3300000   \n",
       "3            4                                                NaN   1200000   \n",
       "4            5                                                NaN         0   \n",
       "...        ...                                                ...       ...   \n",
       "28446   800227                                                NaN         0   \n",
       "29447  1187038                                                NaN         6   \n",
       "29597  1065835                                                NaN   5404446   \n",
       "30336   947650                                                NaN         0   \n",
       "31557  1116492                                                NaN      5000   \n",
       "\n",
       "                                                  genres  \\\n",
       "0                         [{'id': 35, 'name': 'Comedy'}]   \n",
       "1      [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "2                          [{'id': 18, 'name': 'Drama'}]   \n",
       "3      [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
       "4      [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
       "...                                                  ...   \n",
       "28446                      [{'id': 18, 'name': 'Drama'}]   \n",
       "29447  [{'id': 9648, 'name': 'Mystery'}, {'id': 80, '...   \n",
       "29597  [{'id': 53, 'name': 'Thriller'}, {'id': 80, 'n...   \n",
       "30336  [{'id': 16, 'name': 'Animation'}, {'id': 10751...   \n",
       "31557  [{'id': 18, 'name': 'Drama'}, {'id': 27, 'name...   \n",
       "\n",
       "                                                homepage     imdb_id  \\\n",
       "0                                                    NaN   tt2637294   \n",
       "1                                                    NaN   tt0368933   \n",
       "2                      http://sonyclassics.com/whiplash/   tt2582802   \n",
       "3                             http://kahaanithefilm.com/   tt1821480   \n",
       "4                                                    NaN   tt1380152   \n",
       "...                                                  ...         ...   \n",
       "28446  http://a24films.com/films/all-dirt-roads-taste...  tt11534720   \n",
       "29447                     https://www.pioneerpicture.com  tt27097230   \n",
       "29597                                                NaN  tt15654502   \n",
       "30336                                                NaN  tt14506102   \n",
       "31557                          http://www.trettfilms.com  tt27351080   \n",
       "\n",
       "      original_language                            original_title  \\\n",
       "0                    en                    Hot Tub Time Machine 2   \n",
       "1                    en  The Princess Diaries 2: Royal Engagement   \n",
       "2                    en                                  Whiplash   \n",
       "3                    hi                                   Kahaani   \n",
       "4                    ko                                      마린보이   \n",
       "...                 ...                                       ...   \n",
       "28446                en              All Dirt Roads Taste of Salt   \n",
       "29447                kn                                   Manduka   \n",
       "29597                hi                            The Ladykiller   \n",
       "30336                cs            Tonko, Slávka a kúzelné svetlo   \n",
       "31557                en                                      Dial   \n",
       "\n",
       "                                                overview  popularity  ...  \\\n",
       "0      When Lou, who has become the \"father of the In...    6.575393  ...   \n",
       "1      Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
       "2      Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
       "3      Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   \n",
       "4      Marine Boy is the story of a former national s...    1.148070  ...   \n",
       "...                                                  ...         ...  ...   \n",
       "28446  Tender caresses and enveloping embraces are po...    6.058000  ...   \n",
       "29447  A girl suffering from schizophrenia accidental...    3.045000  ...   \n",
       "29597  When a small-town playboy falls in love for a ...    1.700000  ...   \n",
       "30336  Tony has been glowing since the day he was bor...    2.102000  ...   \n",
       "31557  Dani cares for her ill mother who suddenly die...    1.038000  ...   \n",
       "\n",
       "                                          title  \\\n",
       "0                        Hot Tub Time Machine 2   \n",
       "1      The Princess Diaries 2: Royal Engagement   \n",
       "2                                      Whiplash   \n",
       "3                                       Kahaani   \n",
       "4                                    Marine Boy   \n",
       "...                                         ...   \n",
       "28446              All Dirt Roads Taste of Salt   \n",
       "29447                                   Manduka   \n",
       "29597                            The Ladykiller   \n",
       "30336          Tony, Shelly and the Magic Light   \n",
       "31557                                      Dial   \n",
       "\n",
       "                                                keywords  \\\n",
       "0      [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
       "1      [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
       "2      [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
       "3      [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "28446   ['woman director', 'visual poem', 'mississippi']   \n",
       "29447  ['india', 'kannada', 'accidental crime', 'sand...   \n",
       "29597  ['mysterious woman', 'erotic thriller', 'suspe...   \n",
       "30336                                    ['stop motion']   \n",
       "31557       ['psychological thriller', 'phone', 'carer']   \n",
       "\n",
       "                                                    cast  \\\n",
       "0      [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
       "1      [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
       "2      [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
       "3      [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
       "4      [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
       "...                                                  ...   \n",
       "28446  ['Charleen McClure', 'Sheila Atim', 'Moses Ing...   \n",
       "29447  ['Anjala', 'Madhan', 'Bhushan', 'Mysore raju',...   \n",
       "29597  ['Bhumi Pednekar', 'Arjun Kapoor', 'Priyanka B...   \n",
       "30336  ['Michael Polák', 'Antonie Baresová', 'Ivana U...   \n",
       "31557  ['Olivia Bourne', 'Denise Stephenson', 'Greg L...   \n",
       "\n",
       "                                                    crew   revenue  adult  \\\n",
       "0      [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651    NaN   \n",
       "1      [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435    NaN   \n",
       "2      [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000    NaN   \n",
       "3      [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000    NaN   \n",
       "4      [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970    NaN   \n",
       "...                                                  ...       ...    ...   \n",
       "28446                                                NaN     41000  False   \n",
       "29447                                                NaN        10  False   \n",
       "29597                                                NaN       456  False   \n",
       "30336                                                NaN    191018  False   \n",
       "31557                                                NaN      5000  False   \n",
       "\n",
       "                          backdrop_path  video vote_average vote_count  \n",
       "0                                   NaN    NaN          NaN        NaN  \n",
       "1                                   NaN    NaN          NaN        NaN  \n",
       "2                                   NaN    NaN          NaN        NaN  \n",
       "3                                   NaN    NaN          NaN        NaN  \n",
       "4                                   NaN    NaN          NaN        NaN  \n",
       "...                                 ...    ...          ...        ...  \n",
       "28446  /p65KvZIFrlYxB3LZU2e5WtYvmfZ.jpg  False          0.0        0.0  \n",
       "29447  /oXLzPSTw5YoAUU7XcXf88BjICq2.jpg  False          0.0        0.0  \n",
       "29597  /eyDx5sUQscDqDC3PdRbsBNH3BxB.jpg  False          0.0        0.0  \n",
       "30336  /rFdlSLjaf6qrGChWr9gje6eTcbf.jpg  False          0.0        0.0  \n",
       "31557  /6mkQa7QVIC5LLx7tJr7FCgVbyc3.jpg  False          0.0        0.0  \n",
       "\n",
       "[8266 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the 'Online 2017 data.csv' file into a dataframe\n",
    "online = pd.read_csv('Yearly\\Online 2017 data.csv')\n",
    "\n",
    "# Rename the 'Keywords' column to 'keywords' to ensure successful merging\n",
    "online.rename(columns={'Keywords': 'keywords'}, inplace=True)\n",
    "\n",
    "# Concatenate the 'online' dataframe with 'TMDB_df'\n",
    "TMDB_df = pd.concat([online, TMDB_df])\n",
    "\n",
    "# Remove duplicate rows based on the 'imdb_id' column, keeping the first occurrence\n",
    "TMDB_df.drop_duplicates(subset=['imdb_id'], keep='first', inplace=True)\n",
    "\n",
    "# Now, 'TMDB_df' contains the merged data with the online data without duplicates\n",
    "TMDB_df[TMDB_df['revenue']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "cMalURR9B0Gq",
    "outputId": "750d3856-b101-4b59-cd26-50b09382df59"
   },
   "outputs": [],
   "source": [
    "# Read the CSV file 'gross_earnings_domestic_2013-2023.csv' into a dataframe and rename the 'daily earnings' column\n",
    "MOJO_df = pd.read_csv('Additional_Data\\gross_earnings_domestic_2013-2023.csv').rename(columns={'daily earnings': 'gross_earnings_domestic'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1eHOFI1B3eV",
    "outputId": "53abfc16-9db8-43b4-976e-2bdacdf85555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total movies in both dataframes: 3364\n"
     ]
    }
   ],
   "source": [
    "# Create sets of movie titles from 'MOJO_df' and 'TMDB_df'\n",
    "MOJO_set = set(MOJO_df[\"movie\"].to_list())\n",
    "TMDB_set = set(TMDB_df[\"title\"].to_list())\n",
    "\n",
    "# Find the intersection of the two sets to determine the number of movies that exist in both dataframes\n",
    "common_movies = MOJO_set.intersection(TMDB_set)\n",
    "\n",
    "# Print the total number of common movies\n",
    "print(f'Total movies in both dataframes: {len(common_movies)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "15Kr6D704kSb"
   },
   "outputs": [],
   "source": [
    "# Use an inner join to include only rows with matching movie titles in both dataframes\n",
    "merged_df = pd.merge(MOJO_df, TMDB_df, left_on='movie', right_on='title', how='inner')\n",
    "\n",
    "# Remove duplicate rows based on the 'imdb_id' column, keeping the first occurrence\n",
    "merged_df.drop_duplicates(subset=['imdb_id'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UW3ATubLoiuP"
   },
   "outputs": [],
   "source": [
    "#Removing the missing data or data that will not be useful in the model\n",
    "merged_df.drop(columns=['belongs_to_collection','poster_path','status','tagline','crew','adult','backdrop_path','video'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gFCdHGVpt1ql"
   },
   "outputs": [],
   "source": [
    "#Filtering only rows that have revenues\n",
    "final_df=merged_df[merged_df['revenue']!=0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EODPCMuv0N0",
    "outputId": "f1e5dd79-4000-4914-ac76-13385d3c8806"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_countries</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>genres</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>[{'id': 2187, 'name': 'riot'}, {'id': 6091, 'n...</td>\n",
       "      <td>[{'name': 'Screen Yorkshire', 'id': 2690}, {'n...</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 28, 'n...</td>\n",
       "      <td>[{'cast_id': 6, 'character': 'Gary Hook', 'cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>[{'id': 1930, 'name': 'kidnapping'}, {'id': 23...</td>\n",
       "      <td>[{'name': 'Paramount Pictures', 'id': 4}, {'na...</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 878, '...</td>\n",
       "      <td>[{'cast_id': 2, 'character': 'Michelle', 'cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>['kidnapping', 'revenge']</td>\n",
       "      <td>[{'id': 5056, 'logo_path': '/583ITs4w9sK31FnJw...</td>\n",
       "      <td>[{'id': 53, 'name': 'Thriller'}]</td>\n",
       "      <td>['Luke Evans', 'Kelly Reilly', 'Noel Clarke', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>['cia', 'based on novel or book', 'afghanistan...</td>\n",
       "      <td>[{'id': 79529, 'logo_path': '/gVN3k8emmKy4iV4K...</td>\n",
       "      <td>[{'id': 10752, 'name': 'War'}, {'id': 18, 'nam...</td>\n",
       "      <td>['Chris Hemsworth', 'Michael Shannon', 'Michae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>[{'english_name': 'English', 'iso_639_1': 'en'...</td>\n",
       "      <td>['slavery', 'plantation', 'based on memoir or ...</td>\n",
       "      <td>[{'id': 10104, 'logo_path': '/wRn5HnYMGeJHmItR...</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 36, 'name...</td>\n",
       "      <td>['Chiwetel Ejiofor', 'Michael Fassbender', \"Lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                production_countries  \\\n",
       "0   [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]   \n",
       "1  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
       "3   [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]   \n",
       "4  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
       "5  [{'iso_3166_1': 'US', 'name': 'United States o...   \n",
       "\n",
       "                                    spoken_languages  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3  [{'english_name': 'English', 'iso_639_1': 'en'...   \n",
       "4  [{'english_name': 'English', 'iso_639_1': 'en'...   \n",
       "5  [{'english_name': 'English', 'iso_639_1': 'en'...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{'id': 2187, 'name': 'riot'}, {'id': 6091, 'n...   \n",
       "1  [{'id': 1930, 'name': 'kidnapping'}, {'id': 23...   \n",
       "3                          ['kidnapping', 'revenge']   \n",
       "4  ['cia', 'based on novel or book', 'afghanistan...   \n",
       "5  ['slavery', 'plantation', 'based on memoir or ...   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{'name': 'Screen Yorkshire', 'id': 2690}, {'n...   \n",
       "1  [{'name': 'Paramount Pictures', 'id': 4}, {'na...   \n",
       "3  [{'id': 5056, 'logo_path': '/583ITs4w9sK31FnJw...   \n",
       "4  [{'id': 79529, 'logo_path': '/gVN3k8emmKy4iV4K...   \n",
       "5  [{'id': 10104, 'logo_path': '/wRn5HnYMGeJHmItR...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 53, 'name': 'Thriller'}, {'id': 28, 'n...   \n",
       "1  [{'id': 53, 'name': 'Thriller'}, {'id': 878, '...   \n",
       "3                   [{'id': 53, 'name': 'Thriller'}]   \n",
       "4  [{'id': 10752, 'name': 'War'}, {'id': 18, 'nam...   \n",
       "5  [{'id': 18, 'name': 'Drama'}, {'id': 36, 'name...   \n",
       "\n",
       "                                                cast  \n",
       "0  [{'cast_id': 6, 'character': 'Gary Hook', 'cre...  \n",
       "1  [{'cast_id': 2, 'character': 'Michelle', 'cred...  \n",
       "3  ['Luke Evans', 'Kelly Reilly', 'Noel Clarke', ...  \n",
       "4  ['Chris Hemsworth', 'Michael Shannon', 'Michae...  \n",
       "5  ['Chiwetel Ejiofor', 'Michael Fassbender', \"Lu...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['production_countries','spoken_languages','keywords','production_companies','genres','cast']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEyGjonhv1A-",
    "outputId": "9dac4c81-acaa-4f9d-b6cb-f07cc0a22b17"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_k2QjG2Vwjn0"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "# Define a function to convert a date string to a datetime object\n",
    "def convert_date_string_to_datetime(date_string):\n",
    "    try:\n",
    "        return pd.to_datetime(date_string, errors='coerce')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Define a function to extract country names from a string containing a list of dictionaries\n",
    "def extract_countries(production_countries_str):\n",
    "    try:\n",
    "        # Convert the string representation of the list of dictionaries into an actual list of dictionaries\n",
    "        production_countries_list = ast.literal_eval(production_countries_str)\n",
    "\n",
    "        # Extract the country names\n",
    "        return [country['name'] for country in production_countries_list]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Define a function to extract language names from a string containing a list of dictionaries\n",
    "def extract_languages(spoken_languages_str):\n",
    "    try:\n",
    "        # Convert the string representation of the list of dictionaries into an actual list of dictionaries\n",
    "        spoken_languages_list = ast.literal_eval(spoken_languages_str)\n",
    "\n",
    "        # Extract the language names\n",
    "        return [language.get('name', language.get('english_name', 'Unknown')) for language in spoken_languages_list]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Define a function to extract keywords from a string containing a list of dictionaries or strings\n",
    "def extract_keywords(keywords_str):\n",
    "    try:\n",
    "        # Attempt to interpret the string as a list\n",
    "        keywords_list = ast.literal_eval(keywords_str)\n",
    "\n",
    "        # Check if the first element of the list is a dictionary\n",
    "        if isinstance(keywords_list, list) and keywords_list and isinstance(keywords_list[0], dict):\n",
    "            # Extract the keyword names from dictionaries\n",
    "            return [keyword['name'] for keyword in keywords_list]\n",
    "        elif isinstance(keywords_list, list):\n",
    "            # The list already contains keyword names as strings\n",
    "            return keywords_list\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Define a function to extract production company names and create a comma-separated string\n",
    "def extract_production_company_names(production_companies):\n",
    "    # Check if the production companies data is a string and convert to a list if necessary\n",
    "    if isinstance(production_companies, str):\n",
    "        try:\n",
    "            production_companies = json.loads(production_companies.replace(\"'\", \"\\\"\"))\n",
    "        except json.decoder.JSONDecodeError:\n",
    "            return None\n",
    "    # Extract the names of the production companies\n",
    "    if isinstance(production_companies, list):\n",
    "        company_names = [company['name'] for company in production_companies if 'name' in company]\n",
    "        return ', '.join(company_names)  # Use ', ' to separate with a comma and space\n",
    "    return None\n",
    "\n",
    "# Apply the 'extract_production_company_names' function to the 'production_companies' column in 'TMDB_df'\n",
    "TMDB_df['production_companies'] = TMDB_df['production_companies'].apply(extract_production_company_names)\n",
    "\n",
    "# Define a function to extract genres from a string and return them as a list\n",
    "def get_genres(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    elif '[' in x:\n",
    "        genres_list = []\n",
    "        x = x.replace(\"'\", '\"')\n",
    "        for genre_dict in json.loads(x):\n",
    "            genres_list.append(genre_dict['name'])\n",
    "        return genres_list\n",
    "    else:\n",
    "        return [x]\n",
    "\n",
    "# Define a function to extract character names from a string containing a list of dictionaries\n",
    "def extract_character_names(cast_str):\n",
    "    try:\n",
    "        # Convert the string representation of the list of dictionaries into an actual list of dictionaries\n",
    "        cast_list = ast.literal_eval(cast_str)\n",
    "\n",
    "        # Extract the character names using list comprehension\n",
    "        return [cast_member['character'] for cast_member in cast_list]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Define a function to extract spoken languages from a string containing a list of dictionaries\n",
    "def spoken_languages(data):\n",
    "    if pd.isna(data):\n",
    "        return None  # Return None for NaN values\n",
    "    # Replace single-quotes with double-quotes and parse as JSON\n",
    "    data = data.replace(\"'\", '\"')\n",
    "    language_list = json.loads(data)\n",
    "    result = [f\"[{item['iso_639_1']}]\" for item in language_list]\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiPAEi0zxihY",
    "outputId": "ac6c74fc-faf1-4a00-b70b-67e3d80fa376"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['genres'] = final_df['genres'].apply(get_genres)\n",
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['spoken_languages'] = final_df['spoken_languages'].apply(extract_languages)\n",
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['production_countries'] = final_df['production_countries'].apply(extract_countries)\n",
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['release_date'] = pd.to_datetime(final_df['release_date'], errors='coerce')\n",
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['keywords'] = final_df['keywords'].apply(extract_keywords)\n",
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['production_companies'] = final_df['production_companies'].apply(extract_production_company_names)\n",
      "C:\\Users\\anson\\AppData\\Local\\Temp\\ipykernel_15656\\2480591178.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['cast'] = final_df['cast'].apply(extract_character_names)\n"
     ]
    }
   ],
   "source": [
    "# Apply the 'get_genres' function to the 'genres' column to extract and format genre information\n",
    "final_df['genres'] = final_df['genres'].apply(get_genres)\n",
    "\n",
    "# Apply the 'extract_languages' function to the 'spoken_languages' column to extract language information\n",
    "final_df['spoken_languages'] = final_df['spoken_languages'].apply(extract_languages)\n",
    "\n",
    "# Apply the 'extract_countries' function to the 'production_countries' column to extract country information\n",
    "final_df['production_countries'] = final_df['production_countries'].apply(extract_countries)\n",
    "\n",
    "# Convert the 'release_date' column to datetime format, handling any errors by coercing invalid values to NaN\n",
    "final_df['release_date'] = pd.to_datetime(final_df['release_date'], errors='coerce')\n",
    "\n",
    "# Apply the 'extract_keywords' function to the 'keywords' column to extract keyword information\n",
    "final_df['keywords'] = final_df['keywords'].apply(extract_keywords)\n",
    "\n",
    "# Apply the 'extract_production_company_names' function to the 'production_companies' column\n",
    "# to extract and format production company information\n",
    "final_df['production_companies'] = final_df['production_companies'].apply(extract_production_company_names)\n",
    "\n",
    "# Apply the 'extract_character_names' function to the 'cast' column to extract character names\n",
    "final_df['cast'] = final_df['cast'].apply(extract_character_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6f_cgc3kzt-j",
    "outputId": "a5427237-7d34-4eb6-d0a4-376db1baf03b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_countries</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>keywords</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>genres</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[riot, war, british, survival, soldier, ira, e...</td>\n",
       "      <td>Screen Yorkshire, British Film Institute (BFI)...</td>\n",
       "      <td>[Thriller, Action, Drama, War]</td>\n",
       "      <td>[Gary Hook, MRF NCO Lewis, Captain Sandy Brown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[kidnapping, bunker, paranoia, basement, survi...</td>\n",
       "      <td>Paramount Pictures, Bad Robot, Spectrum Effects</td>\n",
       "      <td>[Thriller, Science Fiction, Drama]</td>\n",
       "      <td>[Michelle, Howard Stambler, Emmett DeWitt, Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[kidnapping, revenge]</td>\n",
       "      <td>Head Gear Films, Unstoppable Entertainment</td>\n",
       "      <td>[Thriller]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[cia, based on novel or book, afghanistan, bas...</td>\n",
       "      <td>Torridon Films, Alcon Entertainment, Black Lab...</td>\n",
       "      <td>[War, Drama, Action, History]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[United States of America, United Kingdom]</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[slavery, plantation, based on memoir or autob...</td>\n",
       "      <td>New Regency Pictures, Plan B Entertainment, Ri...</td>\n",
       "      <td>[Drama, History]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         production_countries spoken_languages  \\\n",
       "0                            [United Kingdom]        [English]   \n",
       "1                  [United States of America]        [English]   \n",
       "3                            [United Kingdom]        [English]   \n",
       "4                  [United States of America]        [English]   \n",
       "5  [United States of America, United Kingdom]        [English]   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [riot, war, british, survival, soldier, ira, e...   \n",
       "1  [kidnapping, bunker, paranoia, basement, survi...   \n",
       "3                              [kidnapping, revenge]   \n",
       "4  [cia, based on novel or book, afghanistan, bas...   \n",
       "5  [slavery, plantation, based on memoir or autob...   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  Screen Yorkshire, British Film Institute (BFI)...   \n",
       "1    Paramount Pictures, Bad Robot, Spectrum Effects   \n",
       "3         Head Gear Films, Unstoppable Entertainment   \n",
       "4  Torridon Films, Alcon Entertainment, Black Lab...   \n",
       "5  New Regency Pictures, Plan B Entertainment, Ri...   \n",
       "\n",
       "                               genres  \\\n",
       "0      [Thriller, Action, Drama, War]   \n",
       "1  [Thriller, Science Fiction, Drama]   \n",
       "3                          [Thriller]   \n",
       "4       [War, Drama, Action, History]   \n",
       "5                    [Drama, History]   \n",
       "\n",
       "                                                cast  \n",
       "0  [Gary Hook, MRF NCO Lewis, Captain Sandy Brown...  \n",
       "1  [Michelle, Howard Stambler, Emmett DeWitt, Ben...  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5                                                 []  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['production_countries','spoken_languages','keywords','production_companies','genres','cast']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUbK-D2-0TJJ"
   },
   "outputs": [],
   "source": [
    "# Read the 'Tomato_Score.csv' file into a dataframe named 'tomato'\n",
    "tomato = pd.read_csv('Outputs\\Tomato_Score.csv')\n",
    "\n",
    "# Merge 'tomato' and 'final_df' dataframes based on the 'Movie' column from 'tomato' and the 'title' column from 'final_df'\n",
    "# Use an inner join to include only rows with matching movie titles in both dataframes\n",
    "finalwithtomato_df = pd.merge(tomato, final_df, left_on='Movie', right_on='title', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0cCFART8qvy",
    "outputId": "a4e9edbd-cfe7-48dc-ae20-ab88caacc767"
   },
   "outputs": [],
   "source": [
    "finalwithtomato_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "on4Hs_Jk8tMz",
    "outputId": "8bf16129-543e-4dac-bdc3-2a4a31b23692"
   },
   "outputs": [],
   "source": [
    "finalwithtomato_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4Uy3lpQ894-"
   },
   "outputs": [],
   "source": [
    "# Read the 'Youtube_Movie_Data.csv' file into a dataframe named 'youtube'\n",
    "youtube = pd.read_csv('Outputs\\Youtube_Movie_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9kupZb6bfCm"
   },
   "outputs": [],
   "source": [
    "# Merge 'youtube' and 'finalwithtomato_df' dataframes based on the 'MovieTitle' column from 'youtube' and the 'title' column from 'finalwithtomato_df'\n",
    "# Use an inner join to include only rows with matching movie titles in both dataframes\n",
    "final_df = pd.merge(youtube, finalwithtomato_df, left_on='MovieTitle', right_on='title', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSPXkJaWcbKi"
   },
   "outputs": [],
   "source": [
    "# Drop the 'YouTube Video ID' and 'YouTube Video Title' columns from the 'final_df' dataframe\n",
    "final_df.drop(columns=['YouTube Video ID', 'YouTube Video Title'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEeSKArdcigK",
    "outputId": "e7def77e-b386-4f13-8e97-34cb34fb1ef2"
   },
   "outputs": [],
   "source": [
    "final_df.drop_duplicates(subset=['imdb_id'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgUPe4Xml1Z0"
   },
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV13KEH9o1LI"
   },
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
